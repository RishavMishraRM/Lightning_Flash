{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "touched-summary",
   "metadata": {},
   "source": [
    "In this notebook, we'll go over the basics of lightning Flash by finetuning/predictin with an ImageClassifier on [Hymenoptera Dataset](https://www.kaggle.com/ajayrana/hymenoptera-data) containing ants and bees images.\n",
    "\n",
    "# Finetuning\n",
    "\n",
    "Finetuning consists of four steps:\n",
    " \n",
    " - 1. Train a source neural network model on a source dataset. For computer vision, it is traditionally  the [ImageNet dataset](http://www.image-net.org/search?q=cat). As training is costly, library such as [Torchvion](https://pytorch.org/docs/stable/torchvision/index.html) library supports popular pre-trainer model architectures . In this notebook, we will be using their [resnet-18](https://pytorch.org/hub/pytorch_vision_resnet/).\n",
    " \n",
    " - 2. Create a new neural network  called the target model. Its architecture replicates the source model and parameters, expect the latest layer which is removed. This model without its latest layer is traditionally called a backbone\n",
    " \n",
    " - 3. Add new layers after the backbone where the latest output size is the number of target dataset categories. Those new layers, traditionally called head will be randomly initialized while backbone will conserve its pre-trained weights from ImageNet.\n",
    " \n",
    " - 4. Train the target model on a target dataset, such as Hymenoptera Dataset with ants and bees. However, freezing some layers at training start such as the backbone tends to be more stable. In Flash, it can easily be done with `trainer.finetune(..., strategy=\"freeze\")`. It is also common to `freeze/unfreeze` the backbone. In `Flash`, it can be done with `trainer.finetune(..., strategy=\"freeze_unfreeze\")`. If one wants more control on the unfreeze flow, Flash supports `trainer.finetune(..., strategy=MyFinetuningStrategy())` where `MyFinetuningStrategy` is subclassing `pytorch_lightning.callbacks.BaseFinetuning`.\n",
    " \n",
    " \n",
    "\n",
    " \n",
    "\n",
    "---\n",
    "  - Give us a ‚≠ê [on Github](https://www.github.com/PytorchLightning/pytorch-lightning/)\n",
    "  - Check out [Flash documentation](https://lightning-flash.readthedocs.io/en/latest/)\n",
    "  - Check out [Lightning documentation](https://pytorch-lightning.readthedocs.io/en/latest/)\n",
    "  - Join us [on Slack](https://join.slack.com/t/pytorch-lightning/shared_invite/zt-pw5v393p-qRaDgEk24~EjiZNBpSQFgQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-torture",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install git+https://github.com/PyTorchLightning/lightning-flash.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-region",
   "metadata": {},
   "source": [
    "### The notebook runtime has to be re-started once Flash is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/streamlit/demo-self-driving/issues/17\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    import os\n",
    "    os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flash\n",
    "from flash.core.data.utils import download_data\n",
    "from flash.image import ImageClassificationData, ImageClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-anaheim",
   "metadata": {},
   "source": [
    "## 1. Download data\n",
    "The data are downloaded from a URL, and save in a 'data' directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_data(\"https://pl-flash-data.s3.amazonaws.com/hymenoptera_data.zip\", 'data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-serve",
   "metadata": {},
   "source": [
    "<h2>2. Load the data</h2>\n",
    "\n",
    "Flash Tasks have built-in DataModules that you can use to organize your data. Pass in a train, validation and test folders and Flash will take care of the rest.\n",
    "Creates a ImageClassificationData object from folders of images arranged in this way:</h4>\n",
    "\n",
    "\n",
    "   train/dog/xxx.png\n",
    "   train/dog/xxy.png\n",
    "   train/dog/xxz.png\n",
    "   train/cat/123.png\n",
    "   train/cat/nsdf3.png\n",
    "   train/cat/asd932.png\n",
    "\n",
    "\n",
    "Note: Each sub-folder content will be considered as a new class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = ImageClassificationData.from_folders(\n",
    "    train_folder=\"data/hymenoptera_data/train/\",\n",
    "    val_folder=\"data/hymenoptera_data/val/\",\n",
    "    test_folder=\"data/hymenoptera_data/test/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-groove",
   "metadata": {},
   "source": [
    "###  3. Build the model\n",
    "Create the ImageClassifier task. By default, the ImageClassifier task uses a [resnet-18](https://pytorch.org/hub/pytorch_vision_resnet/) backbone to train or finetune your model.\n",
    "For [Hymenoptera Dataset](https://www.kaggle.com/ajayrana/hymenoptera-data) containing ants and bees images, ``datamodule.num_classes`` will be 2.\n",
    "Backbone can easily be changed with `ImageClassifier(backbone=\"resnet50\")` or you could provide your own `ImageClassifier(backbone=my_backbone)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-timer",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImageClassifier(num_classes=datamodule.num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-sacramento",
   "metadata": {},
   "source": [
    "###  4. Create the trainer. Run once on data\n",
    "\n",
    "The trainer object can be used for training or fine-tuning tasks on new sets of data. \n",
    "\n",
    "You can pass in parameters to control the training routine- limit the number of epochs, run on GPUs or TPUs, etc.\n",
    "\n",
    "For more details, read the  [Trainer Documentation](https://pytorch-lightning.readthedocs.io/en/latest/trainer.html).\n",
    "\n",
    "In this demo, we will limit the fine-tuning to run just one epoch using max_epochs=2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = flash.Trainer(max_epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-contamination",
   "metadata": {},
   "source": [
    "###  5. Finetune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-arrangement",
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "trainer.finetune(model, datamodule=datamodule, strategy=\"freeze_unfreeze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-lobby",
   "metadata": {},
   "source": [
    "###  6. Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-vacuum",
   "metadata": {},
   "source": [
    "###  7. Save it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(\"image_classification_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-express",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-christianity",
   "metadata": {},
   "source": [
    "### 1. Load the model from a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-surrey",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImageClassifier.load_from_checkpoint(\"https://flash-weights.s3.amazonaws.com/image_classification_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-recipe",
   "metadata": {},
   "source": [
    "### 2a. Predict what's on a few images! ants or bees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-johnston",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([\n",
    "    \"data/hymenoptera_data/val/bees/65038344_52a45d090d.jpg\",\n",
    "    \"data/hymenoptera_data/val/bees/590318879_68cf112861.jpg\",\n",
    "    \"data/hymenoptera_data/val/ants/540543309_ddbb193ee5.jpg\",\n",
    "])\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-humanitarian",
   "metadata": {},
   "source": [
    "### 2b. Or generate predictions with a whole folder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-wound",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = ImageClassificationData.from_folders(predict_folder=\"data/hymenoptera_data/predict/\")\n",
    "predictions = flash.Trainer().predict(model, datamodule=datamodule)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
